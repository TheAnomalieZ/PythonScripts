{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Inspired by example from\n",
    "https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent\n",
    "Uses the TensorFlow backend\n",
    "The basic idea is to detect anomalies in a time-series.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from numpy import arange, sin, pi, random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theano version 0.8.2\n",
      "theano is installed in /usr/lib/python2.7/site-packages/theano\n",
      "NumPy version 1.11.1\n",
      "NumPy relaxed strides checking option: False\n",
      "NumPy is installed in /usr/lib64/python2.7/site-packages/numpy\n",
      "Python version 2.7.12 (default, Sep 29 2016, 13:30:34) [GCC 6.2.1 20160916 (Red Hat 6.2.1-2)]\n",
      "nose version 1.3.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/theano/misc/pycuda_init.py:34: UserWarning: PyCUDA import failed in theano.misc.pycuda_init\n",
      "  warnings.warn(\"PyCUDA import failed in theano.misc.pycuda_init\")\n",
      "EE...........E..../usr/lib/python2.7/site-packages/theano/compile/profilemode.py:84: UserWarning: DEPRECATION WARNING: The ProfileMode is deprecated. Use the Theano flags/parameter to theano.function 'profile=True' instead of 'mode=ProfileMode'\n",
      "  \"DEPRECATION WARNING: The ProfileMode is deprecated. \"\n",
      "...../usr/lib64/python2.7/site-packages/numpy/lib/nanfunctions.py:326: RuntimeWarning: All-NaN slice encountered\n",
      "  warnings.warn(\"All-NaN slice encountered\", RuntimeWarning)\n",
      "/usr/lib64/python2.7/site-packages/numpy/lib/nanfunctions.py:227: RuntimeWarning: All-NaN axis encountered\n",
      "  warnings.warn(\"All-NaN axis encountered\", RuntimeWarning)\n",
      ".E........E.............................../usr/lib/python2.7/site-packages/theano/gof/vm.py:818: UserWarning: CVM does not support memory profile, using Stack VM.\n",
      "  'CVM does not support memory profile, using Stack VM.')\n",
      "...........SS.........................................................\n",
      "======================================================================\n",
      "ERROR: Failure: ImportError (No module named nose_parameterized)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/loader.py\", line 418, in loadTestsFromName\n",
      "    addr.filename, addr.module)\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/importer.py\", line 47, in importFromPath\n",
      "    return self.importFromDir(dir_path, fqname)\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/importer.py\", line 94, in importFromDir\n",
      "    mod = load_module(part_fqname, fh, filename, desc)\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/compile/tests/test_builders.py\", line 12, in <module>\n",
      "    from theano.tests import unittest_tools\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/tests/unittest_tools.py\", line 7, in <module>\n",
      "    from nose_parameterized import parameterized\n",
      "ImportError: No module named nose_parameterized\n",
      "\n",
      "======================================================================\n",
      "ERROR: Failure: ImportError (No module named nose_parameterized)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/loader.py\", line 418, in loadTestsFromName\n",
      "    addr.filename, addr.module)\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/importer.py\", line 47, in importFromPath\n",
      "    return self.importFromDir(dir_path, fqname)\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/importer.py\", line 94, in importFromDir\n",
      "    mod = load_module(part_fqname, fh, filename, desc)\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/compile/tests/test_debugmode.py\", line 13, in <module>\n",
      "    from theano.tests import unittest_tools as utt\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/tests/unittest_tools.py\", line 7, in <module>\n",
      "    from nose_parameterized import parameterized\n",
      "ImportError: No module named nose_parameterized\n",
      "\n",
      "======================================================================\n",
      "ERROR: Failure: ImportError (No module named nose_parameterized)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/loader.py\", line 418, in loadTestsFromName\n",
      "    addr.filename, addr.module)\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/importer.py\", line 47, in importFromPath\n",
      "    return self.importFromDir(dir_path, fqname)\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/importer.py\", line 94, in importFromDir\n",
      "    mod = load_module(part_fqname, fh, filename, desc)\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/compile/tests/test_function_module.py\", line 14, in <module>\n",
      "    from theano.tests.unittest_tools import SkipTest\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/tests/unittest_tools.py\", line 7, in <module>\n",
      "    from nose_parameterized import parameterized\n",
      "ImportError: No module named nose_parameterized\n",
      "\n",
      "======================================================================\n",
      "ERROR: Failure: ImportError (No module named nose_parameterized)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/loader.py\", line 418, in loadTestsFromName\n",
      "    addr.filename, addr.module)\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/importer.py\", line 47, in importFromPath\n",
      "    return self.importFromDir(dir_path, fqname)\n",
      "  File \"/usr/lib/python2.7/site-packages/nose/importer.py\", line 94, in importFromDir\n",
      "    mod = load_module(part_fqname, fh, filename, desc)\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/compile/tests/test_ops.py\", line 6, in <module>\n",
      "    from theano.tests import unittest_tools as utt\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/tests/unittest_tools.py\", line 7, in <module>\n",
      "    from nose_parameterized import parameterized\n",
      "ImportError: No module named nose_parameterized\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_sparse_input_aliasing_affecting_inplace_operations (theano.compile.tests.test_pfunc.Test_aliasing_rules)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/compile/tests/test_pfunc.py\", line 715, in test_sparse_input_aliasing_affecting_inplace_operations\n",
      "    from theano.sparse import enable_sparse\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/sparse/__init__.py\", line 19, in <module>\n",
      "    from theano.sparse.basic import *\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/sparse/basic.py\", line 25, in <module>\n",
      "    import theano.tests.unittest_tools as utt\n",
      "  File \"/usr/lib/python2.7/site-packages/theano/tests/unittest_tools.py\", line 7, in <module>\n",
      "    from nose_parameterized import parameterized\n",
      "ImportError: No module named nose_parameterized\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 136 tests in 498.078s\n",
      "\n",
      "FAILED (SKIP=2, errors=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nose.result.TextTestResult run=136 errors=5 failures=0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano\n",
    "theano.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "# Global hyper-parameters\n",
    "sequence_length = 50\n",
    "random_data_dup = 10  # each sample randomly duplicated between 0 and 9 times, see dropin function\n",
    "epochs = 1\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropin(X, y):\n",
    "    \"\"\" The name suggests the inverse of dropout, i.e. adding more samples. See Data Augmentation section at\n",
    "    http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/\n",
    "    :param X: Each row is a training sequence\n",
    "    :param y: Tne target we train and will later predict\n",
    "    :return: new augmented X, y\n",
    "    \"\"\"\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    X_hat = []\n",
    "    y_hat = []\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0, np.random.random_integers(0, random_data_dup)):\n",
    "            X_hat.append(X[i, :])\n",
    "            y_hat.append(y[i])\n",
    "    return np.asarray(X_hat), np.asarray(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSV():\n",
    "    f = open('/home/mani/1.csv/cep/ceptrain.csv')\n",
    "    states = []\n",
    "    try:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            states.append(map(int, row))\n",
    "    finally:\n",
    "        f.close()\n",
    "    train_data = np.array(states)\n",
    "    print train_data.shape\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def z_norm(result):\n",
    "    result = np.float64(result)\n",
    "    result_mean = result.mean()\n",
    "    result_std = result.std()\n",
    "    result -= result_mean\n",
    "    result /= result_std\n",
    "    return result, result_mean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_split_prep_data(train_start, train_end,\n",
    "                          test_start, test_end):\n",
    "    #data = gen_wave()\n",
    "    data = readCSV()\n",
    "    print(\"Length of Data\", len(data))\n",
    "\n",
    "    # train data\n",
    "    print \"Creating train data...\"\n",
    "\n",
    "    result = []\n",
    "    for index in range(train_start, train_end - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result, dtype=np.int8)  # shape (samples, sequence_length)\n",
    "    #result, result_mean = z_norm(result)\n",
    "\n",
    "    #print \"Mean of train data : \", result_mean\n",
    "    print \"Train data shape  : \", result.shape\n",
    "    #print result\n",
    "    train = result[train_start:train_end, :]\n",
    "    #np.random.shuffle(train)  # shuffles in-place\n",
    "    print train.shape\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    #X_train, y_train = dropin(X_train, y_train)\n",
    "\n",
    "    print(\"Shape X_train\", np.shape(X_train))\n",
    "    print(\"Shape y_train\", np.shape(y_train))\n",
    "    \n",
    "    \n",
    "    # test data\n",
    "    print \"Creating test data...\"\n",
    "\n",
    "    result = []\n",
    "    for index in range(test_start, test_end - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result,dtype=np.int8) # shape (samples, sequence_length)\n",
    "    #result, result_mean = z_norm(result)\n",
    "\n",
    "    #print \"Mean of test data : \", result_mean\n",
    "    print \"Test data shape  : \", result.shape\n",
    "\n",
    "    X_test = result[:, :-1]\n",
    "    y_test = result[:, -1]\n",
    "\n",
    "    print(\"Shape X_test\", np.shape(X_test))\n",
    "    print(\"Shape y_test\", np.shape(y_test))\n",
    "\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(676, 1)\n",
      "('Length of Data', 676)\n",
      "Creating train data...\n",
      "Train data shape  :  (550, 50, 1)\n",
      "(550, 50, 1)\n",
      "('Shape X_train', (550, 49, 1))\n",
      "('Shape y_train', (550, 1))\n",
      "Creating test data...\n",
      "Test data shape  :  (24, 50, 1)\n",
      "('Shape X_test', (24, 49, 1))\n",
      "('Shape y_test', (24, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[0],\n",
       "         [0],\n",
       "         [1],\n",
       "         ..., \n",
       "         [2],\n",
       "         [3],\n",
       "         [1]],\n",
       " \n",
       "        [[0],\n",
       "         [1],\n",
       "         [3],\n",
       "         ..., \n",
       "         [3],\n",
       "         [1],\n",
       "         [2]],\n",
       " \n",
       "        [[1],\n",
       "         [3],\n",
       "         [1],\n",
       "         ..., \n",
       "         [1],\n",
       "         [2],\n",
       "         [3]],\n",
       " \n",
       "        ..., \n",
       "        [[3],\n",
       "         [0],\n",
       "         [1],\n",
       "         ..., \n",
       "         [2],\n",
       "         [3],\n",
       "         [1]],\n",
       " \n",
       "        [[0],\n",
       "         [1],\n",
       "         [3],\n",
       "         ..., \n",
       "         [3],\n",
       "         [1],\n",
       "         [2]],\n",
       " \n",
       "        [[1],\n",
       "         [3],\n",
       "         [2],\n",
       "         ..., \n",
       "         [1],\n",
       "         [2],\n",
       "         [2]]], dtype=int8), array([[2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [3],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [3],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [2],\n",
       "        [0],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [0],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0]], dtype=int8), array([[[2],\n",
       "         [3],\n",
       "         [0],\n",
       "         ..., \n",
       "         [3],\n",
       "         [1],\n",
       "         [0]],\n",
       " \n",
       "        [[3],\n",
       "         [0],\n",
       "         [2],\n",
       "         ..., \n",
       "         [1],\n",
       "         [0],\n",
       "         [3]],\n",
       " \n",
       "        [[0],\n",
       "         [2],\n",
       "         [0],\n",
       "         ..., \n",
       "         [0],\n",
       "         [3],\n",
       "         [1]],\n",
       " \n",
       "        ..., \n",
       "        [[3],\n",
       "         [2],\n",
       "         [2],\n",
       "         ..., \n",
       "         [3],\n",
       "         [0],\n",
       "         [2]],\n",
       " \n",
       "        [[2],\n",
       "         [2],\n",
       "         [0],\n",
       "         ..., \n",
       "         [0],\n",
       "         [2],\n",
       "         [2]],\n",
       " \n",
       "        [[2],\n",
       "         [0],\n",
       "         [2],\n",
       "         ..., \n",
       "         [2],\n",
       "         [2],\n",
       "         [2]]], dtype=int8), array([[3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [3]], dtype=int8))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_split_prep_data(0,600,601,675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    layers = {'input': 1, 'hidden1': 5, 'hidden2': 10, 'hidden3': 5, 'output': 1}\n",
    "\n",
    "    model.add(LSTM(\n",
    "            input_length=sequence_length - 1,\n",
    "            input_dim=layers['input'],\n",
    "            output_dim=layers['hidden1'],\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden2'],\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden3'],\n",
    "            return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "            output_dim=layers['output']))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print (\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_network(model=None, data=None):\n",
    "    global_start_time = time.time()\n",
    "\n",
    "    if data is None:\n",
    "        print ('Loading data... ')\n",
    "        # train on first 700 samples and test on next 300 samples (has anomaly)\n",
    "        X_train, y_train, X_test, y_test = get_split_prep_data(0, 100, 101, 175)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = data\n",
    "\n",
    "    print ('\\nData Loaded. Compiling...\\n')\n",
    "\n",
    "    if model is None:\n",
    "        model = build_model()\n",
    "\n",
    "    try:\n",
    "        print(\"Training...\")\n",
    "        model.fit(\n",
    "                X_train, y_train,\n",
    "                batch_size=batch_size, nb_epoch=epochs, validation_split=0.05)\n",
    "        print(\"Predicting...\")\n",
    "        predicted = model.predict(X_test)\n",
    "        print(\"Reshaping predicted\")\n",
    "        predicted = np.reshape(predicted, (predicted.size,))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"prediction exception\")\n",
    "        print ('Training duration (s) : ', time.time() - global_start_time)\n",
    "        return model, y_test, 0\n",
    "\n",
    "    try:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(311)\n",
    "        plt.title(\"Actual Test Signal w/Anomalies\")\n",
    "        plt.plot(y_test[:len(y_test)], 'b')\n",
    "        plt.subplot(312)\n",
    "        plt.title(\"Predicted Signal\")\n",
    "        plt.plot(predicted[:len(y_test)], 'g')\n",
    "        plt.subplot(313)\n",
    "        plt.title(\"Squared Error\")\n",
    "        mse = ((y_test - predicted) ** 2)\n",
    "        plt.plot(mse, 'r')\n",
    "        plt.show()\n",
    "        print(\"success\")\n",
    "        plt.savefig( 'myfig.png' )\n",
    "    except Exception as e:\n",
    "        print(\"plotting exception\")\n",
    "        print (str(e))\n",
    "    print( 'Training duration (s) : ', time.time() - global_start_time)\n",
    "\n",
    "    return model, y_test, predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "(676, 1)\n",
      "('Length of Data', 676)\n",
      "Creating train data...\n",
      "Train data shape  :  (50, 50, 1)\n",
      "(50, 50, 1)\n",
      "('Shape X_train', (50, 49, 1))\n",
      "('Shape y_train', (50, 1))\n",
      "Creating test data...\n",
      "Test data shape  :  (24, 50, 1)\n",
      "('Shape X_test', (24, 49, 1))\n",
      "('Shape y_test', (24, 1))\n",
      "\n",
      "Data Loaded. Compiling...\n",
      "\n",
      "Compilation Time :  0.03329205513\n",
      "Training...\n",
      "Train on 47 samples, validate on 3 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "alloc failed\nApply node that caused the error: AllocEmpty{dtype='float32'}(TensorConstant{50}, Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i0) // (i3 * i0)), i0)}}.0, TensorConstant{10})\nToposort index: 161\nInputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), ()]\nInputs strides: [(), (), ()]\nInputs values: [array(50), array(-1047), array(10)]\nOutputs clients: [[IncSubtensor{InplaceSet;:int64:}(AllocEmpty{dtype='float32'}.0, Rebroadcast{0}.0, Constant{1})]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"<ipython-input-54-68f3acc8e800>\", line 14, in run_network\n    model = build_model()\n  File \"<ipython-input-53-d871dd58c33d>\", line 14, in build_model\n    return_sequences=True))\n  File \"/usr/lib/python2.7/site-packages/keras/models.py\", line 308, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 515, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 573, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 150, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/usr/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 213, in call\n    input_length=input_shape[1])\n  File \"/usr/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 842, in rnn\n    go_backwards=go_backwards)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2b78c553da01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-68f3acc8e800>\u001b[0m in \u001b[0;36mrun_network\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     18\u001b[0m         model.fit(\n\u001b[1;32m     19\u001b[0m                 \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 batch_size=batch_size, nb_epoch=epochs, validation_split=0.05)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    820\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: alloc failed\nApply node that caused the error: AllocEmpty{dtype='float32'}(TensorConstant{50}, Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i0) // (i3 * i0)), i0)}}.0, TensorConstant{10})\nToposort index: 161\nInputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), ()]\nInputs strides: [(), (), ()]\nInputs values: [array(50), array(-1047), array(10)]\nOutputs clients: [[IncSubtensor{InplaceSet;:int64:}(AllocEmpty{dtype='float32'}.0, Rebroadcast{0}.0, Constant{1})]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"<ipython-input-54-68f3acc8e800>\", line 14, in run_network\n    model = build_model()\n  File \"<ipython-input-53-d871dd58c33d>\", line 14, in build_model\n    return_sequences=True))\n  File \"/usr/lib/python2.7/site-packages/keras/models.py\", line 308, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 515, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 573, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 150, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/usr/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 213, in call\n    input_length=input_shape[1])\n  File \"/usr/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 842, in rnn\n    go_backwards=go_backwards)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
