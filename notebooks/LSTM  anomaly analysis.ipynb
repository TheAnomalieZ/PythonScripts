{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Inspired by example from\n",
    "https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent\n",
    "Uses the TensorFlow backend\n",
    "The basic idea is to detect anomalies in a time-series.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from numpy import arange, sin, pi, random\n",
    "import h5py\n",
    "# %matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "# Global hyper-parameters\n",
    "sequence_length = 10\n",
    "epochs = 5\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readCSV():\n",
    "    f = open('../data/cep/ceptrain.csv')\n",
    "    states = []\n",
    "    try:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            states.append(row)\n",
    "    finally:\n",
    "        f.close()\n",
    "    train_data = np.array(states)\n",
    "    print (train_data.shape)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204205, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['0.0'],\n",
       "       ['0.0'],\n",
       "       ['0.0'],\n",
       "       ..., \n",
       "       ['0.0'],\n",
       "       ['0.0'],\n",
       "       ['4.0']], \n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def z_norm(result):\n",
    "    result = np.float64(result)\n",
    "    result_mean = result.mean()\n",
    "    result_std = result.std()\n",
    "    result -= result_mean\n",
    "    result /= result_std\n",
    "    return result, result_mean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_split_prep_data(train_start, train_end,\n",
    "                        test_start, test_end):\n",
    "    #data = gen_wave()\n",
    "    data = readCSV()\n",
    "    print(\"Length of Data\", len(data))\n",
    "\n",
    "    # train data\n",
    "    print(\"Creating train data...\")\n",
    "\n",
    "    result = []\n",
    "    for index in range(train_start, train_end - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result)\n",
    "\n",
    "    result, result_mean = z_norm(result)\n",
    "\n",
    "    print (\"Mean of train data : \", result_mean)\n",
    "    print (\"Train data shape  : \", result.shape)\n",
    "    #print result\n",
    "    train = result[train_start:train_end, :]\n",
    "    #np.random.shuffle(train)  # shuffles in-place\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    #X_train, y_train = dropin(X_train, y_train)\n",
    "\n",
    "    print(\"Shape X_train\", np.shape(X_train))\n",
    "    print(\"Shape y_train\", np.shape(y_train))\n",
    "\n",
    "    # test data\n",
    "    print (\"Creating test data...\")\n",
    "\n",
    "    result = []\n",
    "    for index in range(test_start, test_end - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result)\n",
    "    result, result_mean = z_norm(result)\n",
    "\n",
    "    print (\"Mean of test data : \", result_mean)\n",
    "    print (\"Test data shape  : \", result.shape)\n",
    "\n",
    "    X_test = result[:, :-1]\n",
    "    y_test = result[:, -1]\n",
    "\n",
    "    print(\"Shape X_test\", np.shape(X_test))\n",
    "    print(\"Shape y_test\", np.shape(y_test))\n",
    "\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cep/cep001_pausetime.csv\n",
      "cep/cep002_pausetime.csv\n",
      "cep/cep003_pausetime.csv\n",
      "cep/cep004_pausetime.csv\n",
      "cep/cep005_pausetime.csv\n",
      "cep/cep006_pausetime.csv\n",
      "cep/cep007_pausetime.csv\n"
     ]
    }
   ],
   "source": [
    "trainlist=[]\n",
    "for j in range(1,8):\n",
    "    name = 'cep/cep00'+str(j)+'_pausetime.csv'\n",
    "    print (name)\n",
    "    trainlist.insert(j,name)\n",
    "\n",
    "anomalylist=[]\n",
    "anomalylist.insert(1,'cep/ceptest_pausetime.csv')\n",
    "# for j in range(1,8):\n",
    "#     name = 'cep/cep00'+str(j)+'_pausetime.csv'\n",
    "#     print (name)\n",
    "#     anomalylist.insert(j,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_training_data(trainlist):\n",
    "    series=[]\n",
    "    for i in range(0,len(trainlist)):\n",
    "        series.insert(i,np.array(openFile('../data/'+trainlist[i])))\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def openFile(file):\n",
    "    f = open(file)\n",
    "    try:\n",
    "        reader = csv.reader(f)\n",
    "        floats = []\n",
    "        for row in reader:\n",
    "            floats.append(row)\n",
    "    finally:\n",
    "        f.close()\n",
    "    return floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_anomaly_data(anomalylist):\n",
    "    series=[]\n",
    "    for i in range(0,len(anomalylist)):\n",
    "        series.insert(i,np.array(openFile('../data/'+anomalylist[i])))\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train= get_training_data(trainlist)\n",
    "train_data = np.vstack(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205290, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_anomaly_data():\n",
    "    train= get_training_data(trainlist)\n",
    "    train_data = np.vstack(train)\n",
    "    print(\"Length of Training data\", len(train_data))\n",
    "\n",
    "    # train data\n",
    "    print(\"Creating train data...\")\n",
    "\n",
    "    result = []\n",
    "    for index in range(0, train_data.size- sequence_length):\n",
    "        result.append(train_data[index: index + sequence_length])\n",
    "    result = np.array(result)\n",
    "\n",
    "#     result, result_mean = z_norm(result)\n",
    "\n",
    "#     print (\"Mean of train data : \", result_mean)\n",
    "#     print (\"Train data shape  : \", result.shape)\n",
    "    #print result\n",
    "    train = result[0:train_data.size, :]\n",
    "    #np.random.shuffle(train)  # shuffles in-place\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    #X_train, y_train = dropin(X_train, y_train)\n",
    "\n",
    "    print(\"Shape X_train\", np.shape(X_train))\n",
    "    print(\"Shape y_train\", np.shape(y_train))\n",
    "\n",
    "    # test data\n",
    "    print (\"Creating test data...\")\n",
    "    anomaly = get_anomaly_data(anomalylist)\n",
    "    anomaly_data = np.vstack(anomaly)\n",
    "    \n",
    "    print(\"Length of anomaly data\", len(anomaly_data))\n",
    "    \n",
    "    result = []\n",
    "    for index in range(0, anomaly_data.size - sequence_length):\n",
    "        result.append(anomaly_data[index: index + sequence_length])\n",
    "    result = np.array(result)\n",
    "#     result, result_mean = z_norm(result)\n",
    "\n",
    "#     print (\"Mean of test data : \", result_mean)\n",
    "#     print (\"Test data shape  : \", result.shape)\n",
    "\n",
    "    X_test = result[:, :-1]\n",
    "    y_test = result[:, -1]\n",
    "\n",
    "    print(\"Shape X_test\", np.shape(X_test))\n",
    "    print(\"Shape y_test\", np.shape(y_test))\n",
    "\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training data 205290\n",
      "Creating train data...\n",
      "Shape X_train (205280, 9, 1)\n",
      "Shape y_train (205280, 1)\n",
      "Creating test data...\n",
      "Length of anomaly data 12280\n",
      "Shape X_test (12270, 9, 1)\n",
      "Shape y_test (12270, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        ..., \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']]], \n",
       "       dtype='<U5'), array([['0.0'],\n",
       "        ['0.0'],\n",
       "        ['0.0'],\n",
       "        ..., \n",
       "        ['0.0'],\n",
       "        ['0.0'],\n",
       "        ['0.0']], \n",
       "       dtype='<U5'), array([[['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        ..., \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']],\n",
       " \n",
       "        [['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ..., \n",
       "         ['0.0'],\n",
       "         ['0.0'],\n",
       "         ['0.0']]], \n",
       "       dtype='<U5'), array([['0.0'],\n",
       "        ['0.0'],\n",
       "        ['0.0'],\n",
       "        ..., \n",
       "        ['0.0'],\n",
       "        ['0.0'],\n",
       "        ['0.0']], \n",
       "       dtype='<U5'))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_anomaly_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    layers = {'input': 1, 'hidden1': 10, 'hidden2': 20, 'hidden3': 10, 'output': 1}\n",
    "\n",
    "    model.add(LSTM(\n",
    "            input_length=sequence_length - 1,\n",
    "            input_dim=layers['input'],\n",
    "            output_dim=layers['hidden1'],\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden2'],\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden3'],\n",
    "            return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "            output_dim=layers['output']))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print (\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_network(model=None, data=None):\n",
    "    global_start_time = time.time()\n",
    "\n",
    "    if data is None:\n",
    "        print ('Loading data... ')\n",
    "        # train on first 700 samples and test on next 300 samples (has anomaly)\n",
    "#         X_train, y_train, X_test, y_test = get_split_prep_data(0, 200000,200001, 204206)\n",
    "        X_train, y_train, X_test, y_test = train_anomaly_data()\n",
    "\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = data\n",
    "\n",
    "    print ('\\nData Loaded. Compiling...\\n')\n",
    "\n",
    "    \n",
    "    if model is None:\n",
    "        model = build_model()\n",
    "\n",
    "    try:\n",
    "        print(\"Training...\")\n",
    "        model.fit(\n",
    "                X_train, y_train,\n",
    "                batch_size=batch_size, nb_epoch=epochs, validation_split=0.05)\n",
    "        print(\"Predicting...\")\n",
    "        predicted = model.predict(X_test)\n",
    "        print(\"Reshaping predicted\")\n",
    "        predicted = np.reshape(predicted, (predicted.size,))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"prediction exception\")\n",
    "        print ('Training duration (s) : ', time.time() - global_start_time)\n",
    "        return model, y_test, 0\n",
    "\n",
    "    print( 'Training duration (s) : ', time.time() - global_start_time)\n",
    "\n",
    "    return model, y_test, predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showPlot(Predicted, y_test):\n",
    "    try:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(311)\n",
    "        plt.title(\"Actual Test Signal w/Anomalies\")\n",
    "        plt.plot(y_test[:len(y_test)], 'b')\n",
    "        plt.subplot(312)\n",
    "        plt.title(\"Predicted Signal\")\n",
    "        plt.plot(predicted[:len(y_test)], 'g')\n",
    "        plt.subplot(313)\n",
    "        plt.title(\"Squared Error\")\n",
    "        y_te = np.array(y_test,dtype=float)\n",
    "        pred = np.array(predicted,dtype=float)\n",
    "\n",
    "        mse = ((y_te - pred) ** 2)\n",
    "        plt.plot(mse, 'r')\n",
    "        plt.show()\n",
    "        print(\"success\")\n",
    "        plt.savefig( 'myfig.png' )\n",
    "    except Exception as e:\n",
    "        print(\"plotting exception\")\n",
    "        print (str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "Length of Training data 205290\n",
      "Creating train data...\n",
      "Shape X_train (205280, 9, 1)\n",
      "Shape y_train (205280, 1)\n",
      "Creating test data...\n",
      "Length of anomaly data 12280\n",
      "Shape X_test (12270, 9, 1)\n",
      "Shape y_test (12270, 1)\n",
      "\n",
      "Data Loaded. Compiling...\n",
      "\n",
      "Compilation Time :  0.0958249568939209\n",
      "Training...\n",
      "Train on 195016 samples, validate on 10264 samples\n",
      "Epoch 1/5\n",
      "195016/195016 [==============================] - 369s - loss: 8.1007 - val_loss: 14.8643\n",
      "Epoch 2/5\n",
      "195016/195016 [==============================] - 374s - loss: 8.0984 - val_loss: 14.8677\n",
      "Epoch 3/5\n",
      "195016/195016 [==============================] - 398s - loss: 8.1017 - val_loss: 14.8584\n",
      "Epoch 4/5\n",
      "195016/195016 [==============================] - 374s - loss: 8.0999 - val_loss: 14.8613\n",
      "Epoch 5/5\n",
      "195016/195016 [==============================] - 387s - loss: 8.1004 - val_loss: 14.8687\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  2070.3034267425537\n"
     ]
    }
   ],
   "source": [
    "model,y_test,predicted=run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showPlot(predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
